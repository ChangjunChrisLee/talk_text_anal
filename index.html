<!DOCTYPE html>
<html lang="en"><head>
<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/tabby.min.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.262">
<title>index</title>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
<link rel="stylesheet" href="index_files/libs/revealjs/dist/reset.css">
<link rel="stylesheet" href="index_files/libs/revealjs/dist/reveal.css">
<style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #767676;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #767676;  padding-left: 4px; }
    div.sourceCode
      { color: #545454; background-color: #fefefe; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #545454; } /* Normal */
    code span.al { color: #7928a1; } /* Alert */
    code span.an { color: #696969; } /* Annotation */
    code span.at { color: #a55a00; } /* Attribute */
    code span.bn { color: #7928a1; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #d91e18; } /* ControlFlow */
    code span.ch { color: #008000; } /* Char */
    code span.cn { color: #d91e18; } /* Constant */
    code span.co { color: #696969; } /* Comment */
    code span.cv { color: #696969; font-style: italic; } /* CommentVar */
    code span.do { color: #696969; font-style: italic; } /* Documentation */
    code span.dt { color: #7928a1; } /* DataType */
    code span.dv { color: #7928a1; } /* DecVal */
    code span.er { color: #7928a1; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #a55a00; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #696969; } /* Information */
    code span.kw { color: #d91e18; } /* Keyword */
    code span.op { color: #00769e; } /* Operator */
    code span.ot { color: #d91e18; } /* Other */
    code span.pp { color: #7928a1; } /* Preprocessor */
    code span.sc { color: #00769e; } /* SpecialChar */
    code span.ss { color: #008000; } /* SpecialString */
    code span.st { color: #008000; } /* String */
    code span.va { color: #a55a00; } /* Variable */
    code span.vs { color: #008000; } /* VerbatimString */
    code span.wa { color: #696969; font-style: italic; } /* Warning */
  </style>
<link rel="stylesheet" href="index_files/libs/revealjs/dist/theme/quarto.css" id="theme">
<link href="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
<link href="index_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
<link href="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
<link href="index_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
<style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
<style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section class="slide level2"><div class="cell">

</div>
<p><br></p>
<h1>
Text Mining in Academic Research
</h1>
<h2>
: Methods, Applications, and Challenges
</h2>
<hr>
<p><br></p>
<h5>
<code>Invited Talk</code> <span class="citation" data-cites="서강대학교">@서강대학교</span> 메타버스전문대학원
</h5>
<p>2023-05-09</p>
<p><br></p>
<p><br></p>
<h3>
Changjun Lee
</h3>
<h4>
Hanyang University
</h4>
<h4>
Dep. Media &amp; Social Informatics
</h4>
<p><svg aria-hidden="true" role="img" viewbox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:black;overflow:visible;position:relative;"><path d="M575.8 255.5c0 18-15 32.1-32 32.1h-32l.7 160.2c0 2.7-.2 5.4-.5 8.1V472c0 22.1-17.9 40-40 40H456c-1.1 0-2.2 0-3.3-.1c-1.4 .1-2.8 .1-4.2 .1H416 392c-22.1 0-40-17.9-40-40V448 384c0-17.7-14.3-32-32-32H256c-17.7 0-32 14.3-32 32v64 24c0 22.1-17.9 40-40 40H160 128.1c-1.5 0-3-.1-4.5-.2c-1.2 .1-2.4 .2-3.6 .2H104c-22.1 0-40-17.9-40-40V360c0-.9 0-1.9 .1-2.8V287.6H32c-18 0-32-14-32-32.1c0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7L564.8 231.5c8 7 12 15 11 24z"></path></svg> &nbsp;<a href="https://changjunlee.com/" class="uri">changjunlee.com</a></p>
</section><section id="about-me" class="slide level2"><h2>About me</h2>
<p><br></p>
<div class="columns">
<div class="column" style="width:20%;">
<p><img data-src="img/cj.jpg" width="377"></p>
</div><div class="column" style="width:80%;">
<ul>
<li><p>Computational Social Scientist</p></li>
<li><p>Network Scientist</p></li>
<li><p>Interdisciplinary Scholar</p></li>
</ul>
<blockquote>
<p>My research focuses on <strong><em>utilizing computational methods to tackle a wide range of social phenomena</em></strong>, including technology evolution &amp; regional growth, knowledge management, and technology &amp; media innovation. I am passionate about using technology and data to drive innovation and solve real-world problems.</p>
</blockquote>
<ul>
<li><p><strong>Research</strong> <code>#Innovation</code> <code>#Media</code> <code>#Technology</code> <code>#PublicPolicy</code></p></li>
<li><p><strong>Teaching</strong> <code>#DataScience</code> <code>#culture&amp;tech</code></p></li>
</ul>
</div>
</div>
</section><section id="introduction" class="slide level2"><h2>Introduction</h2>
<hr>
<p><br></p>
<h3 id="importance-of-text-mining-in-academic-research"><strong>Importance of Text Mining in Academic Research</strong></h3>
<div>
<div>
<ul>
<li class="fragment"><p><strong>Growth of digital text data</strong>: Exponential increase in research publications, conference proceedings, and digital repositories.</p></li>
<li class="fragment"><p><strong>Time-saving</strong>: Text mining techniques automate analysis, reducing manual labor and time-consuming tasks.</p></li>
<li class="fragment"><p><strong>Uncovering hidden patterns</strong>: Detects patterns, trends, and relationships in large datasets that are not easily done through manual analysis.</p></li>
<li class="fragment"><p><strong>Enhancing interdisciplinary research</strong>: Facilitates collaboration and knowledge transfer between different research fields by discovering connections and insights across disciplines.</p></li>
<li class="fragment"><p><strong>Importance in Media Studies</strong>: Analyzing vast amounts of media content (news articles, social media posts, multimedia transcripts) <u>to understand public opinion, sentiment, and the impact of media on society</u>. Text mining enables efficient examination of <em>media biases, framing, and agenda-setting</em>, as well as tracking <em>emerging trends and topics.</em></p></li>
</ul>
</div>
</div>
</section><section id="introduction-1" class="slide level2"><h2>Introduction</h2>
<hr>

<img data-src="img/fig_1.png" class="r-stretch"></section><section id="introduction-2" class="slide level2"><h2>Introduction</h2>
<hr>

<img data-src="img/fig_2.png" class="r-stretch"></section><section id="introduction-3" class="slide level2"><h2>Introduction</h2>
<hr>
<h3 id="unlocking-the-power-of-text-data"><strong>Unlocking the Power of Text Data</strong></h3>
<ul>
<li><p>Unveil valuable insights and hidden patterns</p></li>
<li><p>Harness natural language processing (<code>NLP</code>), machine learning (<code>ML</code>), and statistical techniques</p></li>
</ul>
<p><br></p>
<h3 id="text-mining-a-synergy-of-techniques"><strong>Text Mining: A Synergy of Techniques</strong></h3>
<ol type="1">
<li><p><strong>Data Collection</strong>: Gathering textual data from diverse sources</p></li>
<li><p><strong>Pre-processing</strong>: Cleaning and transforming raw text for analysis</p></li>
<li><p><strong>Analysis</strong>: Employing NLP, machine learning, and statistical methods to uncover patterns</p></li>
<li><p><strong>Interpretation</strong>: Making sense of the results and deriving actionable insights</p></li>
<li><p><strong>Visualization</strong>: Effectively presenting findings through engaging visual aids</p></li>
</ol></section><section id="overview-of-the-talk" class="slide level2"><h2>Overview of the talk</h2>
<hr>
<h3 id="text-mining-techniques"><strong>🛠️ Text Mining Techniques</strong></h3>
<ul>
<li>Discovering powerful tools and methodologies</li>
</ul>
<p><br></p>
<h3 id="applications-in-academic-research"><strong>🎓 Applications in Academic Research</strong></h3>
<ul>
<li>Exploring the impact of text mining across disciplines</li>
</ul>
<p><br></p>
<h3 id="challenges-and-limitations"><strong>⚠️ Challenges and Limitations</strong></h3>
<ul>
<li>Navigating the hurdles and constraints</li>
</ul>
<p><br></p>
<h3 id="future-directions-and-conclusion"><strong>🚀 Future Directions and Conclusion</strong></h3>
<ul>
<li>Envisioning the evolving landscape of text mining</li>
</ul></section><section id="text-mining-techniques-1" class="slide level2"><h2>Text Mining Techniques</h2>
<hr>
<p><strong>A.</strong> <code>Pre-processing:</code> The foundation for accurate analysis (70% time &amp; labour)</p>
<p><br></p>
<p><strong>B.</strong> <code>Feature Extraction:</code> Transforming text into meaningful representations</p>
<p><br></p>
<p><strong>C.</strong> <code>Text Classification:</code> Categorizing documents based on content</p>
<p><br></p>
<p><strong>D.</strong> <code>Text Clustering:</code> Grouping similar documents together</p>
<p><br></p>
<p><strong>E.</strong> <code>Sentiment Analysis:</code> Decoding emotions and opinions in text</p>
<p><br></p>
<p><strong>F.</strong> <code>Named Entity Recognition:</code> Identifying and classifying entities in text</p>
<p><br></p>
<p><strong>G.</strong> <code>Relation Extraction:</code> Discovering relationships between entities</p>
</section><section id="text-mining-techniques-2" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="pre-processing">Pre-processing</h3>
<h4 id="tokenization"><strong>Tokenization</strong></h4>
<blockquote>
<p>Splitting text into individual words or tokens</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a>text <span class="ot">&lt;-</span> <span class="st">"Text mining is an important technique in academic research."</span></span>
<span id="cb1-2"><a href="#cb1-2"></a>text_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">line =</span> <span class="dv">1</span>, <span class="at">text =</span> text)</span>
<span id="cb1-3"><a href="#cb1-3"></a>text_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 2
   line text                                                       
  &lt;dbl&gt; &lt;chr&gt;                                                      
1     1 Text mining is an important technique in academic research.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>tokens <span class="ot">&lt;-</span> text_df <span class="sc">%&gt;%</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>  <span class="fu">unnest_tokens</span>(word, text)</span>
<span id="cb3-3"><a href="#cb3-3"></a>tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 9 × 2
   line word     
  &lt;dbl&gt; &lt;chr&gt;    
1     1 text     
2     1 mining   
3     1 is       
4     1 an       
5     1 important
6     1 technique
7     1 in       
8     1 academic 
9     1 research </code></pre>
</div>
</div>
</section><section id="text-mining-techniques-3" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="pre-processing-1">Pre-processing</h3>
<h4 id="stop-word-removal"><strong>Stop word removal</strong></h4>
<blockquote>
<p>Removing common words that do not contribute to meaning</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="fu">data</span>(<span class="st">"stop_words"</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a>stop_words</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1,149 × 2
   word        lexicon
   &lt;chr&gt;       &lt;chr&gt;  
 1 a           SMART  
 2 a's         SMART  
 3 able        SMART  
 4 about       SMART  
 5 above       SMART  
 6 according   SMART  
 7 accordingly SMART  
 8 across      SMART  
 9 actually    SMART  
10 after       SMART  
# ℹ 1,139 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>tokens_clean <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>  <span class="fu">anti_join</span>(stop_words)</span>
<span id="cb7-3"><a href="#cb7-3"></a>tokens_clean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 2
   line word     
  &lt;dbl&gt; &lt;chr&gt;    
1     1 text     
2     1 mining   
3     1 technique
4     1 academic 
5     1 research </code></pre>
</div>
</div>
</section><section id="text-mining-techniques-4" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="pre-processing-2">Pre-processing</h3>
<h4 id="stemming-and-lemmatization"><strong>Stemming and Lemmatization</strong></h4>
<blockquote>
<p>Reducing words to their root or base form</p>
<p>한글에서는 형태소 분석 (명사, 동사, 형용사 등으로 분해)</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>tokens_root <span class="ot">&lt;-</span> tokens_clean <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="#cb9-2"></a>  <span class="fu">mutate</span>(<span class="at">lemma =</span> <span class="fu">lemmatize_words</span>(word))</span>
<span id="cb9-3"><a href="#cb9-3"></a>tokens_root</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
   line word      lemma    
  &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    
1     1 text      text     
2     1 mining    mine     
3     1 technique technique
4     1 academic  academic 
5     1 research  research </code></pre>
</div>
</div>
</section><section id="text-mining-techniques-5" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="feature-extraction">Feature Extraction</h3>
<h4 id="bag-of-words"><strong>Bag of Words</strong></h4>
<blockquote>
<p>Creating a document-term matrix with word frequencies</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>texts <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Text mining is important in academic research."</span>,</span>
<span id="cb11-2"><a href="#cb11-2"></a>           <span class="st">"Feature extraction is a crucial step in text mining."</span>,</span>
<span id="cb11-3"><a href="#cb11-3"></a>           <span class="st">"Cats and dogs are popular pets."</span>,</span>
<span id="cb11-4"><a href="#cb11-4"></a>           <span class="st">"Elephants are large animals."</span>,</span>
<span id="cb11-5"><a href="#cb11-5"></a>           <span class="st">"Whales are mammals that live in the ocean."</span>)</span>
<span id="cb11-6"><a href="#cb11-6"></a></span>
<span id="cb11-7"><a href="#cb11-7"></a>text_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">doc_id =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(texts), <span class="at">text =</span> texts)</span>
<span id="cb11-8"><a href="#cb11-8"></a>text_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 2
  doc_id text                                                
   &lt;int&gt; &lt;chr&gt;                                               
1      1 Text mining is important in academic research.      
2      2 Feature extraction is a crucial step in text mining.
3      3 Cats and dogs are popular pets.                     
4      4 Elephants are large animals.                        
5      5 Whales are mammals that live in the ocean.          </code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>tokens <span class="ot">&lt;-</span> text_df <span class="sc">%&gt;%</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>  <span class="fu">unnest_tokens</span>(word, text)</span>
<span id="cb13-3"><a href="#cb13-3"></a>tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 2
   doc_id word      
    &lt;int&gt; &lt;chr&gt;     
 1      1 text      
 2      1 mining    
 3      1 is        
 4      1 important 
 5      1 in        
 6      1 academic  
 7      1 research  
 8      2 feature   
 9      2 extraction
10      2 is        
# ℹ 24 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a><span class="co"># Create a Bag of Words representation</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>bow <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb15-3"><a href="#cb15-3"></a>  <span class="fu">count</span>(doc_id, word) <span class="sc">%&gt;%</span></span>
<span id="cb15-4"><a href="#cb15-4"></a>  <span class="fu">spread</span>(<span class="at">key =</span> word, <span class="at">value =</span> n, <span class="at">fill =</span> <span class="dv">0</span>)</span>
<span id="cb15-5"><a href="#cb15-5"></a>bow</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 28
  doc_id     a academic   and animals   are  cats crucial  dogs elephants
   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1      1     0        1     0       0     0     0       0     0         0
2      2     1        0     0       0     0     0       1     0         0
3      3     0        0     1       0     1     1       0     1         0
4      4     0        0     0       1     1     0       0     0         1
5      5     0        0     0       0     1     0       0     0         0
# ℹ 18 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;</code></pre>
</div>
</div>
</section><section id="text-mining-techniques-6" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="feature-extraction-1">Feature Extraction</h3>
<h4 id="term-frequency-inverse-document-frequency-tf-idf"><strong>Term Frequency-Inverse Document Frequency (TF-IDF)</strong></h4>
<blockquote>
<p>Weighting words <span class="math inline">\(W_{(t,d)}\)</span> based on their importance within and across documents to see how the term <strong><em>t</em></strong> is original (or unique) is in a document <strong><em>d</em></strong></p>
</blockquote>
<p><span class="math display">\[
W_{(t,d)}=tf_{(t,d)} \times idf_{(t)}
\]</span> <span class="math display">\[
W_{(t,d)}=tf_{(t,d)} \times log(\frac{N}{df_{t}})
\]</span></p>
<ul>
<li><p><span class="math inline">\(t\)</span> : a term</p></li>
<li><p><span class="math inline">\(d\)</span> : a document</p></li>
<li><p><span class="math inline">\(tf_{t,d}\)</span> : frequency of term <span class="math inline">\(t\)</span> (e.g.&nbsp;a word) in doc <span class="math inline">\(d\)</span> (e.g.&nbsp;a sentence or an article)</p></li>
<li><p><span class="math inline">\(df_{term}\)</span> : # of documents containing the term</p></li>
<li><p><span class="math inline">\(N\)</span> : total number of documents</p></li>
</ul>
<blockquote>
<p>A high <span class="math inline">\(tf_{t,d}\)</span> indicates that the term is highly significant within the document, while a high <span class="math inline">\(df_{t}\)</span> suggests that the term is widely used across various documents (e.g., common verbs). Multiplying by <span class="math inline">\(idf_{t}\)</span> helps to account for the term’s universality. Ultimately, tf-idf effectively captures a term’s uniqueness and importance, taking into consideration its prevalence across documents.</p>
</blockquote>
<hr>
<p>As an example,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1"></a><span class="co"># Calculate the TF-IDF scores</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>tf_idf <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb17-3"><a href="#cb17-3"></a>  <span class="fu">count</span>(doc_id, word) <span class="sc">%&gt;%</span></span>
<span id="cb17-4"><a href="#cb17-4"></a>  <span class="fu">bind_tf_idf</span>(word, doc_id, n)</span>
<span id="cb17-5"><a href="#cb17-5"></a>tf_idf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 6
   doc_id word           n    tf   idf tf_idf
    &lt;int&gt; &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
 1      1 academic       1 0.143 1.61  0.230 
 2      1 important      1 0.143 1.61  0.230 
 3      1 in             1 0.143 0.511 0.0730
 4      1 is             1 0.143 0.916 0.131 
 5      1 mining         1 0.143 0.916 0.131 
 6      1 research       1 0.143 1.61  0.230 
 7      1 text           1 0.143 0.916 0.131 
 8      2 a              1 0.111 1.61  0.179 
 9      2 crucial        1 0.111 1.61  0.179 
10      2 extraction     1 0.111 1.61  0.179 
# ℹ 24 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Spread into a wide format</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>tf_idf_matrix <span class="ot">&lt;-</span> tf_idf <span class="sc">%&gt;%</span></span>
<span id="cb19-3"><a href="#cb19-3"></a>  <span class="fu">select</span>(doc_id, word, tf_idf) <span class="sc">%&gt;%</span></span>
<span id="cb19-4"><a href="#cb19-4"></a>  <span class="fu">spread</span>(<span class="at">key =</span> word, <span class="at">value =</span> tf_idf, <span class="at">fill =</span> <span class="dv">0</span>)</span>
<span id="cb19-5"><a href="#cb19-5"></a>tf_idf_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 28
  doc_id     a academic   and animals    are  cats crucial  dogs elephants
   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1      1 0        0.230 0       0     0      0       0     0         0    
2      2 0.179    0     0       0     0      0       0.179 0         0    
3      3 0        0     0.268   0     0.0851 0.268   0     0.268     0    
4      4 0        0     0       0.402 0.128  0       0     0         0.402
5      5 0        0     0       0     0.0639 0       0     0         0    
# ℹ 18 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;</code></pre>
</div>
</div>
<hr>
<p>Another example: Moon vs.&nbsp;Park speech</p>
<ul>
<li>Compare two speeches based on the just frequency of words</li>
</ul>
<p><img data-src="https://changjunlee.com/teaching/media_ds/about/NLP_2_files/figure-html/unnamed-chunk-16-1.png"></p>
<ul>
<li>Compare based on TF-IDF</li>
</ul>
<p><img data-src="https://changjunlee.com/teaching/media_ds/about/NLP_2_files/figure-html/unnamed-chunk-37-1.png"></p>
</section><section id="text-mining-techniques-7" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="feature-extraction-2">Feature Extraction</h3>
<h4 id="word-embeddings"><strong>Word Embeddings</strong></h4>
<blockquote>
<p>Mapping words to continuous vector spaces based on their semantic relationships</p>
</blockquote>
<div class="columns">
<div class="column" style="width:40%;">
<p><img data-src="https://www.researchgate.net/profile/Dingcheng-Li-2/publication/332892222/figure/fig2/AS:755762527739904@1557199236483/2D-PCA-projection-of-word-embeddings-Five-different-word-clusters-are-shown_W640.jpg"></p>
</div><div class="column" style="width:60%;">
<ul>
<li><p>Represents words as fixed-size vectors in continuous space</p></li>
<li><p>Captures semantic relationships and linguistic patterns between words</p></li>
<li><p>Common algorithms: <code>Word2Vec</code>, <code>GloVe</code>, <code>FastText</code> → <code>chatGPT</code></p></li>
<li><p>Preserves semantic and syntactic properties in <strong>high-dimensional vector spaces</strong></p></li>
<li><p>Words with similar meanings or usage patterns are closer in vector space</p></li>
<li><p><strong>Applications</strong>: sentiment analysis, document classification, language translation, information retrieval</p></li>
</ul>
</div>
</div>
</section><section id="text-mining-techniques-8" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="text-classification">Text Classification</h3>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-1-1">Algorithms in use</a></li>
<li><a href="#tabset-1-2">For example (Spam mail classifier)</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1">
<ul>
<li><p>Naïve Bayes</p></li>
<li><p>Support Vector Machines</p></li>
<li><p>Neural Networks</p></li>
<li><p>Decision Trees</p></li>
</ul>
</div>
<div id="tabset-1-2">
<p><strong>Bayes’ Theorem</strong></p>
<blockquote>
<p>Bayes’ theorem is a fundamental theorem in probability theory that describes the relationship between the conditional probabilities of two events (here, A and B). It states that the probability of event A given event B is equal to the probability of event B given event A multiplied by the probability of event A, divided by the probability of event B. Mathematically, this can be written as:</p>
</blockquote>
<p><span class="math display">\[
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(P(A|B)\)</span> is the probability of event A given event B (known as the <strong><em>posterior probability</em></strong>)</p></li>
<li><p><span class="math inline">\(P(B|A)\)</span> is the probability of event B given event A (known as the <strong><em>likelihood</em></strong>)</p></li>
<li><p><span class="math inline">\(P(A)\)</span> is the probability of event A (known as the <strong><em>prior probability</em></strong>)</p></li>
<li><p><span class="math inline">\(P(B)\)</span> is the probability of event B (known as the <strong><em>evidence</em></strong>)</p></li>
</ul>
<p><br></p>
<p><strong>The Naive Bayes Algorithm</strong></p>
<blockquote>
<p>The Naive Bayes algorithm uses Bayes’ theorem to predict the probability of each class label given a set of observed features. The algorithm assumes that the features are conditionally independent given the class label, which allows the algorithm to simplify the calculations involved in determining the probability of each class label.</p>
</blockquote>
<p>Let <span class="math inline">\(X = (X_1, X_2, ..., X_n)\)</span> represent the set of observed features, and let Y represent the class label. The goal is to predict the probability of each class label given X, i.e.&nbsp;<span class="math inline">\(P(Y|X)\)</span>. Using Bayes’ theorem, we can write:</p>
<p><span class="math display">\[
P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(P(Y|X)\)</span> is the posterior probability of Y given X</p></li>
<li><p><span class="math inline">\(P(X|Y)\)</span> is the likelihood of X given Y</p></li>
<li><p><span class="math inline">\(P(Y)\)</span> is the prior probability of Y</p></li>
<li><p><span class="math inline">\(P(X)\)</span> is the evidence</p></li>
</ul>
<p><br></p>
<p>The Naive Bayes algorithm assumes that the features <span class="math inline">\(X_1, X_2, ..., X_n\)</span> are conditionally independent given Y, which means that:</p>
<p><span class="math display">\[
P(X|Y) = P(X_1|Y) \times P(X_2|Y) \times \ldots \times P(X_n|Y)
\]</span></p>
<p><br></p>
<p>Using this assumption, we can rewrite the equation for <span class="math inline">\(P(Y|X)\)</span> as:</p>
<p><span class="math display">\[
P(Y|X) = \frac{P(Y)P(X_1|Y)P(X_2|Y) \cdots P(X_n|Y)}{P(X)}
\]</span></p>
<p><br></p>
<p>The evidence <span class="math inline">\(P(X)\)</span> is a constant for a given set of features X, so we can ignore it for the purposes of classification. Therefore, we can simplify the equation to:</p>
<p><span class="math display">\[
P(Y|X) \propto P(Y) \times P(X_1|Y) \times P(X_2|Y) \times \ldots \times P(X_n|Y)
\]</span></p>
<p><br></p>
<p>The Naive Bayes algorithm calculates the likelihoods <span class="math inline">\(P(X_i|Y)\)</span> for each feature and class label from the training data, and uses these likelihoods to predict the probability of each class label given a new set of features. The algorithm selects the class label with the highest probability as the predicted class label.</p>
<p><br></p>
<ul>
<li>You’ve got mail like this</li>
</ul>
<blockquote>
<p>Hello Dear,</p>
<p>I’d like to offer the bes tchance to buy <strong><em>Viagra</em></strong>.</p>
<p>If you are interested …</p>
<p>The <strong>benefit</strong> you get is that …</p>
<p>Also want to suggest a good <strong>fund</strong>..</p>
<p>Amount of 100 <strong>MillionUS</strong>$ …</p>
<p>hope to hear from you.</p>
<p>Yours sincerely,</p>
</blockquote>
<ul>
<li>Calculate probabilities <span class="math inline">\(P(Ham|Viagra)\)</span> and <span class="math inline">\(P(Spam|Viagra)\)</span> and Compare those two!</li>
</ul>
<p><span class="math display">\[
P(Ham|Viagra) = \frac{P(Viagra|Ham)P(Ham)}{P(Viagra)}
\]</span> <span class="math display">\[
P(Spam|Viagra) = \frac{P(Viagra|Spam)P(Spam)}{P(Viagra)}
\]</span></p>
</div>
</div>
</div>
</section><section id="text-mining-techniques-9" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="text-clustering">Text Clustering</h3>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-2-1">K-means Clustering</a></li>
<li><a href="#tabset-2-2">Hierarchical Clustering</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1">
<ul>
<li><p>Partitional clustering method that assigns documents to a fixed number of clusters</p></li>
<li><p>Suitable for larger datasets</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1"></a><span class="co"># Pre-processing and feature extraction (TF-IDF) from previous example</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>tf_idf_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 28
  doc_id     a academic   and animals    are  cats crucial  dogs elephants
   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1      1 0        0.230 0       0     0      0       0     0         0    
2      2 0.179    0     0       0     0      0       0.179 0         0    
3      3 0        0     0.268   0     0.0851 0.268   0     0.268     0    
4      4 0        0     0       0.402 0.128  0       0     0         0.402
5      5 0        0     0       0     0.0639 0       0     0         0    
# ℹ 18 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># K-means clustering</span></span>
<span id="cb23-2"><a href="#cb23-2"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb23-3"><a href="#cb23-3"></a>k <span class="ot">&lt;-</span> <span class="dv">3</span>  <span class="co"># Number of clusters</span></span>
<span id="cb23-4"><a href="#cb23-4"></a>kmeans_model <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(tf_idf_matrix[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">centers =</span> k)</span>
<span id="cb23-5"><a href="#cb23-5"></a>clusters <span class="ot">&lt;-</span> kmeans_model<span class="sc">$</span>cluster</span>
<span id="cb23-6"><a href="#cb23-6"></a></span>
<span id="cb23-7"><a href="#cb23-7"></a><span class="co"># Assigning clusters to original data</span></span>
<span id="cb23-8"><a href="#cb23-8"></a>text_df <span class="sc">%&gt;%</span> </span>
<span id="cb23-9"><a href="#cb23-9"></a>  <span class="fu">mutate</span>(<span class="at">cluster =</span> clusters)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
  doc_id text                                                 cluster
   &lt;int&gt; &lt;chr&gt;                                                  &lt;int&gt;
1      1 Text mining is important in academic research.             1
2      2 Feature extraction is a crucial step in text mining.       1
3      3 Cats and dogs are popular pets.                            2
4      4 Elephants are large animals.                               3
5      5 Whales are mammals that live in the ocean.                 1</code></pre>
</div>
</div>
</div>
<div id="tabset-2-2">
<ul>
<li><p>Agglomerative clustering method that builds a tree of clusters</p></li>
<li><p>Suitable for smaller datasets</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1"></a><span class="co"># Pre-processing and feature extraction (TF-IDF)</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>tf_idf_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 28
  doc_id     a academic   and animals    are  cats crucial  dogs elephants
   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1      1 0        0.230 0       0     0      0       0     0         0    
2      2 0.179    0     0       0     0      0       0.179 0         0    
3      3 0        0     0.268   0     0.0851 0.268   0     0.268     0    
4      4 0        0     0       0.402 0.128  0       0     0         0.402
5      5 0        0     0       0     0.0639 0       0     0         0    
# ℹ 18 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1"></a><span class="co"># Hierarchical clustering</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>dist_matrix <span class="ot">&lt;-</span> <span class="fu">dist</span>(tf_idf_matrix[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">method =</span> <span class="st">"euclidean"</span>)</span>
<span id="cb27-3"><a href="#cb27-3"></a>dist_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          1         2         3         4
2 0.5668202                              
3 0.7631048 0.7491481                    
4 0.8469394 0.8343861 0.9204641          
5 0.6760124 0.6617837 0.7791871 0.8582969</code></pre>
</div>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(dist_matrix, <span class="at">method =</span> <span class="st">"ward.D2"</span>)</span>
<span id="cb29-2"><a href="#cb29-2"></a><span class="fu">plot</span>(hc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-8-1.png" width="960"></p>
</div>
</div>
</div>
</div>
</div>
</section><section id="text-mining-techniques-10" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-1">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>

<img data-src="img/fig_6.png" class="r-stretch"></section><section id="text-mining-techniques-11" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-2">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-1">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>

<img data-src="img/fig_7.png" class="r-stretch"></section><section id="text-mining-techniques-12" class="slide level2"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-3">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-2">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>
<p><br></p>
<ul>
<li>
<p>대용량 문서자료 내에 잠재된 주제를 어떻게 파악할 수 있을까?</p>
<ul>
<li><p>SNS: 사람들이 어떤 주제로 교류하고 있는지?</p></li>
<li><p>뉴스기사: 어떠한 내용들이 보도되고 있는지?</p></li>
<li><p>논문/특허: 어떠한 내용들이 연구개발되고 있는지?</p></li>
<li><p>제품/서비스리뷰: 고객들이 제품/서비스에 대해 어떠한 생각을 가지고 있는지?</p></li>
</ul>
</li>
</ul></section><section id="text-mining-techniques-13" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-4">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-3">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>
<ul>
<li>
<p>대량의 문서자료의 분석에 많이 쓰이는 분석도구</p>
<ul>
<li>문서 내 잠재되어있는 토픽(주제)를 식별함</li>
</ul>
</li>
<li>
<p>토픽은 단어들 사이의 공동출현패턴을 기반으로 식별됨</p>
<ul>
<li><p>함께 나타나는 경향이 짙은 단어들의 확률적 조합으로 ’토픽’을 식별</p></li>
<li><p>확률적 조합이기 때문에 한단어가 여러 토픽에 속할수 있음</p></li>
</ul>
</li>
<li>
<p>한 단어가 여러 토픽(주제)에서 가지는 다양한 맥락적 의미를 분석할 수 있음</p>
<ul>
<li><p>예) “타격”이라는 단어가 경제 기사와 스포츠 기사에서 가지는 의미?</p></li>
<li><p>예) “cell”이라는 단어가 생물학 논문과 연료전지 관련 논문에서 가지는 의미?</p></li>
</ul>
</li>
<li>
<p>자료수집 범위에 따라 아주 세부적인 맥락 차이도 분석가능</p>
<ul>
<li>예) 신기술 관련 문서 집합을 분석했을 때, 똑같이 “자동차”라는 단어가 비중있게 등장하지만 세부적인 맥락은 “전기”자동차와 “자율주행” 자동차로 나뉨</li>
</ul>
</li>
<li>
<p>식별된 토픽을 구성하는 상위 단어들의 구성을 관찰한 후, 연구자가 해당 토픽이 무슨내용인지 유추</p>
<ul>
<li>해석적 여지가 많은 탐색적 방법론</li>
</ul>
</li>
</ul></section><section id="text-mining-techniques-14" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-5">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-4">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>

<img data-src="img/fig_8.png" class="r-stretch"></section><section id="text-mining-techniques-15" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<hr>
<h3 id="text-clustering-6">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-5">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>

<img data-src="img/fig_9.png" class="r-stretch"></section><section id="text-mining-techniques-16" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="text-clustering-7">Text Clustering</h3>
<h4 id="latent-dirichlet-allocation-lda-a.k.a.-topic-modeling-6">
<strong>Latent Dirichlet Allocation (LDA)</strong> (a.k.a. topic modeling)</h4>
<ul>
<li><p>Probabilistic topic modeling method that assigns documents to a mixture of topics</p></li>
<li><p>Suitable for discovering latent topics in text data</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1"></a><span class="fu">library</span>(topicmodels)</span>
<span id="cb30-2"><a href="#cb30-2"></a></span>
<span id="cb30-3"><a href="#cb30-3"></a><span class="co"># Pre-processing and feature extraction (Bag of Words)</span></span>
<span id="cb30-4"><a href="#cb30-4"></a>tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 2
   doc_id word      
    &lt;int&gt; &lt;chr&gt;     
 1      1 text      
 2      1 mining    
 3      1 is        
 4      1 important 
 5      1 in        
 6      1 academic  
 7      1 research  
 8      2 feature   
 9      2 extraction
10      2 is        
# ℹ 24 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1"></a>dtm <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb32-2"><a href="#cb32-2"></a>  <span class="fu">count</span>(doc_id, word) <span class="sc">%&gt;%</span></span>
<span id="cb32-3"><a href="#cb32-3"></a>  <span class="fu">cast_dtm</span>(doc_id, word, n)</span>
<span id="cb32-4"><a href="#cb32-4"></a>dtm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;&lt;DocumentTermMatrix (documents: 5, terms: 27)&gt;&gt;
Non-/sparse entries: 34/101
Sparsity           : 75%
Maximal term length: 10
Weighting          : term frequency (tf)</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1"></a><span class="co"># LDA topic modeling</span></span>
<span id="cb34-2"><a href="#cb34-2"></a>k <span class="ot">&lt;-</span> <span class="dv">2</span>  <span class="co"># Number of topics</span></span>
<span id="cb34-3"><a href="#cb34-3"></a>lda_model <span class="ot">&lt;-</span> <span class="fu">LDA</span>(dtm, <span class="at">k =</span> k, <span class="at">control =</span> <span class="fu">list</span>(<span class="at">seed =</span> <span class="dv">42</span>))</span>
<span id="cb34-4"><a href="#cb34-4"></a>gamma <span class="ot">&lt;-</span> <span class="fu">posterior</span>(lda_model)<span class="sc">$</span>topics</span>
<span id="cb34-5"><a href="#cb34-5"></a></span>
<span id="cb34-6"><a href="#cb34-6"></a><span class="co"># Assigning topics to original data</span></span>
<span id="cb34-7"><a href="#cb34-7"></a>text_df <span class="sc">%&gt;%</span> </span>
<span id="cb34-8"><a href="#cb34-8"></a>  <span class="fu">mutate</span>(<span class="at">topic =</span> <span class="fu">apply</span>(gamma, <span class="dv">1</span>, which.max))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 3
  doc_id text                                                 topic
   &lt;int&gt; &lt;chr&gt;                                                &lt;int&gt;
1      1 Text mining is important in academic research.           1
2      2 Feature extraction is a crucial step in text mining.     1
3      3 Cats and dogs are popular pets.                          2
4      4 Elephants are large animals.                             2
5      5 Whales are mammals that live in the ocean.               2</code></pre>
</div>
</div>
</section><section id="text-mining-techniques-17" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="sentiment-analysis">Sentiment Analysis</h3>
<div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-3-1">Lexicon-based methods</a></li>
<li><a href="#tabset-3-2">Machine learning-based methods</a></li>
<li><a href="#tabset-3-3">Deep learning-based methods</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1">
<ul>
<li><p>Utilize pre-defined lists of words with associated sentiment scores</p></li>
<li><p>Calculate overall sentiment by aggregating scores of individual words</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1"></a><span class="co"># Pre-processing</span></span>
<span id="cb36-2"><a href="#cb36-2"></a>tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 34 × 2
   doc_id word      
    &lt;int&gt; &lt;chr&gt;     
 1      1 text      
 2      1 mining    
 3      1 is        
 4      1 important 
 5      1 in        
 6      1 academic  
 7      1 research  
 8      2 feature   
 9      2 extraction
10      2 is        
# ℹ 24 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1"></a><span class="co"># Sentiment analysis using NRC lexicon</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>sentiments_nrc <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb38-3"><a href="#cb38-3"></a>  <span class="fu">inner_join</span>(<span class="fu">get_sentiments</span>(<span class="st">"nrc"</span>), <span class="at">by =</span> <span class="st">"word"</span>) </span>
<span id="cb38-4"><a href="#cb38-4"></a>sentiments_nrc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 7 × 3
  doc_id word      sentiment
   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;    
1      1 important positive 
2      1 important trust    
3      1 academic  positive 
4      1 academic  trust    
5      2 feature   positive 
6      2 crucial   positive 
7      2 crucial   trust    </code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1"></a>sentiments_nrc <span class="sc">%&gt;%</span> </span>
<span id="cb40-2"><a href="#cb40-2"></a>  <span class="fu">group_by</span>(doc_id, sentiment) <span class="sc">%&gt;%</span> </span>
<span id="cb40-3"><a href="#cb40-3"></a>  <span class="fu">count</span>(sentiment) <span class="sc">%&gt;%</span> </span>
<span id="cb40-4"><a href="#cb40-4"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">as.factor</span>(doc_id), </span>
<span id="cb40-5"><a href="#cb40-5"></a>             <span class="at">y =</span> n, <span class="at">fill =</span> sentiment)) <span class="sc">+</span></span>
<span id="cb40-6"><a href="#cb40-6"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">'identity'</span>,</span>
<span id="cb40-7"><a href="#cb40-7"></a>           <span class="at">position =</span> <span class="st">'fill'</span>) <span class="sc">+</span></span>
<span id="cb40-8"><a href="#cb40-8"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Document"</span>, <span class="at">y =</span> <span class="cn">NULL</span>) <span class="sc">+</span></span>
<span id="cb40-9"><a href="#cb40-9"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-10-1.png" width="960"></p>
</div>
</div>
</div>
<div id="tabset-3-2">
<ul>
<li><p>Train a supervised machine learning model on labeled sentiment data</p></li>
<li><p>Apply the trained model to predict sentiment of new text</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1"></a><span class="co"># Pre-processing and feature extraction (TF-IDF) from previous example</span></span>
<span id="cb41-2"><a href="#cb41-2"></a>tf_idf_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 28
  doc_id     a academic   and animals    are  cats crucial  dogs elephants
   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1      1 0        0.230 0       0     0      0       0     0         0    
2      2 0.179    0     0       0     0      0       0.179 0         0    
3      3 0        0     0.268   0     0.0851 0.268   0     0.268     0    
4      4 0        0     0       0.402 0.128  0       0     0         0.402
5      5 0        0     0       0     0.0639 0       0     0         0    
# ℹ 18 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1"></a><span class="co"># Train a Random Forest model</span></span>
<span id="cb43-2"><a href="#cb43-2"></a>train_data <span class="ot">&lt;-</span> tf_idf_matrix <span class="sc">%&gt;%</span></span>
<span id="cb43-3"><a href="#cb43-3"></a>  <span class="fu">left_join</span>(sentiments_nrc, <span class="at">by =</span> <span class="st">"doc_id"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb43-4"><a href="#cb43-4"></a>  <span class="fu">relocate</span>(sentiment, <span class="at">.after =</span> doc_id) <span class="sc">%&gt;%</span> </span>
<span id="cb43-5"><a href="#cb43-5"></a>  drop_na <span class="sc">%&gt;%</span> </span>
<span id="cb43-6"><a href="#cb43-6"></a>  <span class="fu">select</span>(<span class="sc">-</span>doc_id) </span>
<span id="cb43-7"><a href="#cb43-7"></a>train_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 7 × 29
  sentiment     a academic   and animals   are  cats crucial  dogs elephants
  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
1 positive  0        0.230     0       0     0     0   0         0         0
2 trust     0        0.230     0       0     0     0   0         0         0
3 positive  0        0.230     0       0     0     0   0         0         0
4 trust     0        0.230     0       0     0     0   0         0         0
5 positive  0.179    0         0       0     0     0   0.179     0         0
6 positive  0.179    0         0       0     0     0   0.179     0         0
7 trust     0.179    0         0       0     0     0   0.179     0         0
# ℹ 19 more variables: extraction &lt;dbl&gt;, feature &lt;dbl&gt;, important &lt;dbl&gt;,
#   `in` &lt;dbl&gt;, is &lt;dbl&gt;, large &lt;dbl&gt;, live &lt;dbl&gt;, mammals &lt;dbl&gt;, mining &lt;dbl&gt;,
#   ocean &lt;dbl&gt;, pets &lt;dbl&gt;, popular &lt;dbl&gt;, research &lt;dbl&gt;, step &lt;dbl&gt;,
#   text &lt;dbl&gt;, that &lt;dbl&gt;, the &lt;dbl&gt;, whales &lt;dbl&gt;, word &lt;chr&gt;</code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1"></a>model_rf <span class="ot">&lt;-</span> <span class="fu">rpart</span>(<span class="st">"sentiment ~ a + academic + crucial"</span>, </span>
<span id="cb45-2"><a href="#cb45-2"></a>                         <span class="at">data =</span> train_data)</span>
<span id="cb45-3"><a href="#cb45-3"></a><span class="co"># Predict sentiment for new text</span></span>
<span id="cb45-4"><a href="#cb45-4"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_rf, <span class="at">newdata =</span> tf_idf_matrix)</span>
<span id="cb45-5"><a href="#cb45-5"></a>predictions</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      positive     trust
[1,] 0.5714286 0.4285714
[2,] 0.5714286 0.4285714
[3,] 0.5714286 0.4285714
[4,] 0.5714286 0.4285714
[5,] 0.5714286 0.4285714</code></pre>
</div>
</div>
</div>
<div id="tabset-3-3">
<ul>
<li><p>Train a deep learning model, such as a Recurrent Neural Network (RNN) or Transformer, on labeled sentiment data</p></li>
<li><p>Apply the trained model to predict sentiment of new text</p></li>
</ul>
</div>
</div>
</div>
</section><section id="text-mining-techniques-18" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="named-entity-recognition">Named Entity Recognition</h3>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-4-1">Rule-based methods</a></li>
<li><a href="#tabset-4-2">Machine learning-based methods</a></li>
<li><a href="#tabset-4-3">Deep learning-based methods</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1">
<ul>
<li><p>Utilize predefined patterns and rules to identify entities in text</p></li>
<li><p>Examples include regular expressions and dictionary lookups</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1"></a><span class="co"># Example data</span></span>
<span id="cb47-2"><a href="#cb47-2"></a>text_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb47-3"><a href="#cb47-3"></a>  <span class="at">doc_id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb47-4"><a href="#cb47-4"></a>  <span class="at">text =</span> <span class="fu">c</span>(</span>
<span id="cb47-5"><a href="#cb47-5"></a>    <span class="st">"John works at Google."</span>,</span>
<span id="cb47-6"><a href="#cb47-6"></a>    <span class="st">"Alice is employed by Microsoft."</span>,</span>
<span id="cb47-7"><a href="#cb47-7"></a>    <span class="st">"Bob is a researcher at OpenAI."</span></span>
<span id="cb47-8"><a href="#cb47-8"></a>  ),</span>
<span id="cb47-9"><a href="#cb47-9"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span></span>
<span id="cb47-10"><a href="#cb47-10"></a>)</span>
<span id="cb47-11"><a href="#cb47-11"></a>text_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  doc_id                            text
1      1           John works at Google.
2      2 Alice is employed by Microsoft.
3      3  Bob is a researcher at OpenAI.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1"></a><span class="co"># Define a simple regular expression pattern for person-organization relations</span></span>
<span id="cb49-2"><a href="#cb49-2"></a>relation_pattern <span class="ot">&lt;-</span> <span class="st">"([A-Z][a-z]+) (?:works at|is employed by|is a researcher at) ([A-Z][A-Za-z]+)"</span></span>
<span id="cb49-3"><a href="#cb49-3"></a></span>
<span id="cb49-4"><a href="#cb49-4"></a><span class="co"># Extract relations from text</span></span>
<span id="cb49-5"><a href="#cb49-5"></a><span class="fu">str_match_all</span>(text_df<span class="sc">$</span>text, relation_pattern) <span class="sc">%&gt;%</span></span>
<span id="cb49-6"><a href="#cb49-6"></a>  <span class="fu">lapply</span>(<span class="cf">function</span>(matches) {</span>
<span id="cb49-7"><a href="#cb49-7"></a>    <span class="cf">if</span> (<span class="fu">nrow</span>(matches) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb49-8"><a href="#cb49-8"></a>      <span class="fu">return</span>(<span class="fu">data.frame</span>(</span>
<span id="cb49-9"><a href="#cb49-9"></a>        <span class="at">person =</span> matches[, <span class="dv">2</span>],</span>
<span id="cb49-10"><a href="#cb49-10"></a>        <span class="at">organization =</span> matches[, <span class="dv">3</span>],</span>
<span id="cb49-11"><a href="#cb49-11"></a>        <span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span></span>
<span id="cb49-12"><a href="#cb49-12"></a>      ))</span>
<span id="cb49-13"><a href="#cb49-13"></a>    } <span class="cf">else</span> {</span>
<span id="cb49-14"><a href="#cb49-14"></a>      <span class="fu">return</span>(<span class="cn">NULL</span>)</span>
<span id="cb49-15"><a href="#cb49-15"></a>    }</span>
<span id="cb49-16"><a href="#cb49-16"></a>  }) <span class="sc">%&gt;%</span> <span class="fu">do.call</span>(rbind,.)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  person organization
1   John       Google
2  Alice    Microsoft
3    Bob       OpenAI</code></pre>
</div>
</div>
</div>
<div id="tabset-4-2">
<ul>
<li><p>Train a supervised machine learning model on labeled entity data</p></li>
<li><p>Apply the trained model to recognize entities in new text</p></li>
</ul>
</div>
<div id="tabset-4-3">
<ul>
<li><p>Train a deep learning model, such as a BiLSTM-CRF or Transformer, on labeled entity data</p></li>
<li><p>Apply the trained model to recognize entities in new text</p></li>
</ul>
</div>
</div>
</div>
</section><section id="text-mining-techniques-19" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="relation-extraction">Relation Extraction</h3>
<div class="panel-tabset">
<ul id="tabset-5" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-5-1"><strong>Theoretical Foundation</strong></a></li>
<li><a href="#tabset-5-2"><strong>Implications for Research</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1">
<ul>
<li><p>Keyword network analysis is grounded in social network analysis (SNA) and graph theory.</p></li>
<li><p>SNA allows researchers to study relationships, interactions, and connections between entities (in this case, keywords).</p></li>
<li><p>Graph theory provides a mathematical framework to analyze and visualize complex networks, allowing for a better understanding of the structure and organization of the data.</p></li>
</ul>
</div>
<div id="tabset-5-2">
<ol type="1">
<li><p><strong>Identify key topics and themes</strong>: Keyword network analysis can help researchers identify the most important keywords or concepts in a given text dataset, providing insight into the main topics and themes.</p></li>
<li><p><strong>Uncover hidden relationships</strong>: By visualizing and analyzing the connections between keywords, researchers can discover hidden relationships and patterns in the data that might not be apparent through traditional text analysis methods.</p></li>
<li><p><strong>Facilitate interdisciplinary research</strong>: Keyword network analysis can reveal connections between seemingly unrelated research areas, facilitating interdisciplinary collaboration and knowledge transfer.</p></li>
<li><p><strong>Inform research design and sampling</strong>: By identifying the most influential keywords or topics in a dataset, researchers can target their efforts on specific areas of interest, enabling more efficient research design and sampling strategies.</p></li>
<li><p><strong>Support hypothesis generation and validation</strong>: The visualization and analysis of keyword networks can help researchers generate and validate hypotheses about the relationships between different concepts, leading to a deeper understanding of the underlying phenomena.</p></li>
</ol>
</div>
</div>
</div>
</section><section id="text-mining-techniques-20" class="slide level2 scrollable"><h2>Text Mining Techniques</h2>
<h3 id="relation-extraction-1">Relation Extraction</h3>
<div class="panel-tabset">
<ul id="tabset-6" class="panel-tabset-tabby">
<li><a data-tabby-default="" href="#tabset-6-1"><strong>A. Preprocessing and extracting keywords</strong></a></li>
<li><a href="#tabset-6-2"><strong>B. Co-occurrence matrix and network</strong></a></li>
<li><a href="#tabset-6-3"><strong>C. Analyzing keyword network</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1">
<ul>
<li><p>Tokenization</p></li>
<li><p>Stop word removal</p></li>
<li><p>Stemming or lemmatization (optional)</p></li>
<li><p><strong>Sample text</strong>: 6 sentences</p></li>
</ul>
<blockquote>
<p>Text mining and data mining are essential techniques in data science, and they help analyze large amounts of textual data. Machine learning, natural language processing, and deep learning are crucial techniques for text mining and data analysis. Text mining can reveal insights in large collections of documents, uncovering hidden patterns and trends. Big data analytics involves data mining, machine learning, text mining, and statistical analysis. Sentiment analysis is a popular application of text mining, natural language processing, and machine learning, often used for social media analytics. Data visualization plays a significant role in understanding patterns and trends in data mining results, making complex information more accessible.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1"></a><span class="co"># Example dataset</span></span>
<span id="cb51-2"><a href="#cb51-2"></a>text_data <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb51-3"><a href="#cb51-3"></a>  <span class="at">doc_id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,</span>
<span id="cb51-4"><a href="#cb51-4"></a>  <span class="at">text =</span> <span class="fu">c</span>(<span class="st">"Text mining and data mining are essential techniques in data science, and they help analyze large amounts of textual data."</span>,</span>
<span id="cb51-5"><a href="#cb51-5"></a>           <span class="st">"Machine learning, natural language processing, and deep learning are crucial techniques for text mining and data analysis."</span>,</span>
<span id="cb51-6"><a href="#cb51-6"></a>           <span class="st">"Text mining can reveal insights in large collections of documents, uncovering hidden patterns and trends."</span>,</span>
<span id="cb51-7"><a href="#cb51-7"></a>           <span class="st">"Big data analytics involves data mining, machine learning, text mining, and statistical analysis."</span>,</span>
<span id="cb51-8"><a href="#cb51-8"></a>           <span class="st">"Sentiment analysis is a popular application of text mining, natural language processing, and machine learning, often used for social media analytics."</span>,</span>
<span id="cb51-9"><a href="#cb51-9"></a>           <span class="st">"Data visualization plays a significant role in understanding patterns and trends in data mining results, making complex information more accessible."</span>)</span>
<span id="cb51-10"><a href="#cb51-10"></a>)</span>
<span id="cb51-11"><a href="#cb51-11"></a>text_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 2
  doc_id text                                                                   
   &lt;int&gt; &lt;chr&gt;                                                                  
1      1 Text mining and data mining are essential techniques in data science, …
2      2 Machine learning, natural language processing, and deep learning are c…
3      3 Text mining can reveal insights in large collections of documents, unc…
4      4 Big data analytics involves data mining, machine learning, text mining…
5      5 Sentiment analysis is a popular application of text mining, natural la…
6      6 Data visualization plays a significant role in understanding patterns …</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1"></a><span class="co"># Tokenization</span></span>
<span id="cb53-2"><a href="#cb53-2"></a>tokens <span class="ot">&lt;-</span> text_data <span class="sc">%&gt;%</span></span>
<span id="cb53-3"><a href="#cb53-3"></a>  <span class="fu">unnest_tokens</span>(word, text) <span class="sc">%&gt;%</span></span>
<span id="cb53-4"><a href="#cb53-4"></a>  <span class="fu">anti_join</span>(stop_words) <span class="sc">%&gt;%</span></span>
<span id="cb53-5"><a href="#cb53-5"></a>  <span class="fu">group_by</span>(doc_id) <span class="sc">%&gt;%</span></span>
<span id="cb53-6"><a href="#cb53-6"></a>  <span class="fu">count</span>(word, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span>
<span id="cb53-7"><a href="#cb53-7"></a>tokens</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 67 × 3
# Groups:   doc_id [6]
   doc_id word          n
    &lt;int&gt; &lt;chr&gt;     &lt;int&gt;
 1      1 data          3
 2      1 mining        2
 3      2 learning      2
 4      4 data          2
 5      4 mining        2
 6      6 data          2
 7      1 amounts       1
 8      1 analyze       1
 9      1 essential     1
10      1 science       1
# ℹ 57 more rows</code></pre>
</div>
</div>
</div>
<div id="tabset-6-2">
<ul>
<li><p>Calculate word co-occurrence matrix</p></li>
<li><p>Convert co-occurrence matrix to a graph object</p></li>
<li><p>Visualize the keyword network</p></li>
</ul>
<div class="cell" data-fig.dpi="200">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1"></a><span class="co"># Calculate co-occurrence matrix</span></span>
<span id="cb55-2"><a href="#cb55-2"></a>co_occurrence_matrix <span class="ot">&lt;-</span> tokens <span class="sc">%&gt;%</span></span>
<span id="cb55-3"><a href="#cb55-3"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb55-4"><a href="#cb55-4"></a>  <span class="fu">pairwise_count</span>(word, doc_id, <span class="at">sort =</span> <span class="cn">TRUE</span>)</span>
<span id="cb55-5"><a href="#cb55-5"></a></span>
<span id="cb55-6"><a href="#cb55-6"></a>co_occurrence_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 586 × 3
   item1    item2        n
   &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;
 1 text     mining       5
 2 mining   text         5
 3 mining   data         4
 4 data     mining       4
 5 text     data         3
 6 learning mining       3
 7 analysis mining       3
 8 machine  mining       3
 9 mining   learning     3
10 text     learning     3
# ℹ 576 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1"></a><span class="co"># Filter edges and create graph object</span></span>
<span id="cb57-2"><a href="#cb57-2"></a>filtered_edges <span class="ot">&lt;-</span> co_occurrence_matrix <span class="sc">%&gt;%</span></span>
<span id="cb57-3"><a href="#cb57-3"></a>  <span class="fu">filter</span>(n <span class="sc">&gt;=</span> <span class="dv">2</span>)</span>
<span id="cb57-4"><a href="#cb57-4"></a></span>
<span id="cb57-5"><a href="#cb57-5"></a>keyword_network <span class="ot">&lt;-</span> <span class="fu">graph_from_data_frame</span>(filtered_edges)</span>
<span id="cb57-6"><a href="#cb57-6"></a>keyword_network</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>IGRAPH 0350ef0 DN-- 13 88 -- 
+ attr: name (v/c), n (e/n)
+ edges from 0350ef0 (vertex names):
 [1] text      -&gt;mining   mining    -&gt;text     mining    -&gt;data    
 [4] data      -&gt;mining   text      -&gt;data     learning  -&gt;mining  
 [7] analysis  -&gt;mining   machine   -&gt;mining   mining    -&gt;learning
[10] text      -&gt;learning analysis  -&gt;learning machine   -&gt;learning
[13] data      -&gt;text     learning  -&gt;text     analysis  -&gt;text    
[16] machine   -&gt;text     mining    -&gt;analysis learning  -&gt;analysis
[19] text      -&gt;analysis machine   -&gt;analysis mining    -&gt;machine 
[22] learning  -&gt;machine  text      -&gt;machine  analysis  -&gt;machine 
+ ... omitted several edges</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1"></a><span class="co"># Visualize the keyword network</span></span>
<span id="cb59-2"><a href="#cb59-2"></a><span class="fu">ggraph</span>(keyword_network, <span class="at">layout =</span> <span class="st">"fr"</span>) <span class="sc">+</span></span>
<span id="cb59-3"><a href="#cb59-3"></a>  <span class="fu">geom_edge_link</span>(<span class="fu">aes</span>(<span class="at">edge_alpha =</span> n), <span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb59-4"><a href="#cb59-4"></a>  <span class="fu">geom_node_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb59-5"><a href="#cb59-5"></a>  <span class="fu">geom_node_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> name), <span class="at">vjust =</span> <span class="dv">1</span>, <span class="at">hjust =</span> <span class="dv">1</span>, <span class="at">size =</span> <span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb59-6"><a href="#cb59-6"></a>  <span class="fu">theme_graph</span>(<span class="at">base_family =</span> <span class="st">"Arial"</span>) <span class="sc">+</span></span>
<span id="cb59-7"><a href="#cb59-7"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Keyword Co-occurrence Network"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-14-1.png" width="960"></p>
</div>
</div>
<p><br></p>
<p>To understand the graph better, let’s examine some of the connections:</p>
<ol type="1">
<li><p><strong><code>text -&gt; mining</code></strong>: The keyword ‘text’ is connected to the keyword ‘mining’. This edge represents that ‘text’ and ‘mining’ co-occur in the dataset, forming the term ‘text mining’.</p></li>
<li><p><strong><code>mining -&gt; data</code></strong>: The keyword ‘mining’ is connected to the keyword ‘data’, indicating that these two terms appear together, forming the term ‘data mining’.</p></li>
<li><p><strong><code>learning -&gt; machine</code></strong>: The keyword ‘learning’ is connected to the keyword ‘machine’, representing the co-occurrence of these two terms, forming ‘machine learning’.</p></li>
<li><p><strong><code>analysis -&gt; text</code></strong>: The keyword ‘analysis’ is connected to the keyword ‘text’, suggesting that these two terms co-occur in the dataset, forming the term ‘text analysis’.</p></li>
</ol>
<p>From this graph, you can observe the following:</p>
<ul>
<li><p>Keywords related to data analysis techniques, such as ‘<em>text mining</em>’, ‘<em>data mining</em>’, ‘<em>machine learning</em>’, and ‘<em>analysis</em>’, are strongly connected, indicating that they are frequently discussed together in the dataset.</p></li>
<li><p>The term ‘<em>text mining</em>’ is connected to ‘<em>data mining</em>’, ‘<em>machine learning</em>’, and ‘<em>analysis</em>’, suggesting that these techniques are closely related and are often mentioned in the context of text analysis.</p></li>
<li><p>The term ‘machine learning’ is connected to ‘<em>text mining</em>’, ‘<em>data mining</em>’, and ‘analysis’, highlighting its importance and relevance to different data analysis techniques.</p></li>
</ul>
</div>
<div id="tabset-6-3">
<ul>
<li><p><code>Degree centrality</code>: Number of connections for each node</p></li>
<li><p><code>Betweenness centrality</code>: Importance of a node as a connector in the network</p></li>
<li><p><code>Community detection</code>: Clustering of nodes in the network</p></li>
</ul>
<div class="cell" data-fig.dpi="200">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1"></a><span class="co"># Degree centrality</span></span>
<span id="cb60-2"><a href="#cb60-2"></a>degree_centrality <span class="ot">&lt;-</span> <span class="fu">degree</span>(keyword_network)</span>
<span id="cb60-3"><a href="#cb60-3"></a><span class="co"># Betweenness centrality</span></span>
<span id="cb60-4"><a href="#cb60-4"></a>betweenness_centrality <span class="ot">&lt;-</span> <span class="fu">betweenness</span>(keyword_network)</span>
<span id="cb60-5"><a href="#cb60-5"></a></span>
<span id="cb60-6"><a href="#cb60-6"></a><span class="fu">tibble</span>(<span class="at">node =</span> <span class="fu">names</span>(degree_centrality), </span>
<span id="cb60-7"><a href="#cb60-7"></a>       <span class="at">degree_centrality =</span> <span class="fu">degree</span>(keyword_network)) <span class="sc">%&gt;%</span> </span>
<span id="cb60-8"><a href="#cb60-8"></a>  <span class="fu">left_join</span>(</span>
<span id="cb60-9"><a href="#cb60-9"></a>    <span class="fu">tibble</span>(<span class="at">node =</span> <span class="fu">names</span>(degree_centrality), </span>
<span id="cb60-10"><a href="#cb60-10"></a>       <span class="at">betweenness_centrality =</span> <span class="fu">betweenness</span>(keyword_network))</span>
<span id="cb60-11"><a href="#cb60-11"></a>  ) <span class="ot">-&gt;</span> node_data</span>
<span id="cb60-12"><a href="#cb60-12"></a>node_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 3
   node       degree_centrality betweenness_centrality
   &lt;chr&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;
 1 text                      20                    8.8
 2 mining                    24                   48.8
 3 data                      12                    2  
 4 learning                  18                    2.8
 5 analysis                  18                    2.8
 6 machine                   18                    2.8
 7 techniques                 6                    0  
 8 language                  14                    0  
 9 natural                   14                    0  
10 processing                14                    0  
11 patterns                   4                    0  
12 trends                     4                    0  
13 analytics                 10                    0  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1"></a><span class="co"># Degree - Btw mat</span></span>
<span id="cb62-2"><a href="#cb62-2"></a>node_data <span class="sc">%&gt;%</span> </span>
<span id="cb62-3"><a href="#cb62-3"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> degree_centrality,</span>
<span id="cb62-4"><a href="#cb62-4"></a>             <span class="at">y =</span> betweenness_centrality)) <span class="sc">+</span></span>
<span id="cb62-5"><a href="#cb62-5"></a>  <span class="fu">geom_text_repel</span>(<span class="fu">aes</span>(<span class="at">label =</span> node), <span class="at">size =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-15-1.png" width="960"></p>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1"></a><span class="co"># Degree - Btw mat (2)</span></span>
<span id="cb63-2"><a href="#cb63-2"></a>node_data <span class="sc">%&gt;%</span> </span>
<span id="cb63-3"><a href="#cb63-3"></a>  <span class="fu">filter</span>(betweenness_centrality <span class="sc">&lt;</span> <span class="dv">7</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb63-4"><a href="#cb63-4"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> degree_centrality,</span>
<span id="cb63-5"><a href="#cb63-5"></a>             <span class="at">y =</span> betweenness_centrality)) <span class="sc">+</span></span>
<span id="cb63-6"><a href="#cb63-6"></a>  <span class="fu">geom_text_repel</span>(<span class="fu">aes</span>(<span class="at">label =</span> node), <span class="at">size =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-15-2.png" width="960"></p>
</div>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1"></a><span class="co"># Community detection using Louvain method</span></span>
<span id="cb64-2"><a href="#cb64-2"></a></span>
<span id="cb64-3"><a href="#cb64-3"></a><span class="co"># Convert the directed graph to an undirected graph</span></span>
<span id="cb64-4"><a href="#cb64-4"></a>undirected_keyword_network <span class="ot">&lt;-</span> <span class="fu">as.undirected</span>(keyword_network, <span class="at">mode =</span> <span class="st">"collapse"</span>)</span>
<span id="cb64-5"><a href="#cb64-5"></a></span>
<span id="cb64-6"><a href="#cb64-6"></a><span class="co"># Perform community detection using the Louvain algorithm</span></span>
<span id="cb64-7"><a href="#cb64-7"></a>louvain_communities <span class="ot">&lt;-</span> <span class="fu">cluster_louvain</span>(undirected_keyword_network)</span>
<span id="cb64-8"><a href="#cb64-8"></a></span>
<span id="cb64-9"><a href="#cb64-9"></a><span class="co"># Print the community assignments</span></span>
<span id="cb64-10"><a href="#cb64-10"></a><span class="fu">print</span>(louvain_communities)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>IGRAPH clustering multi level, groups: 3, mod: 0.1
+ groups:
  $`1`
  [1] "text"       "data"       "techniques"
  
  $`2`
  [1] "mining"   "patterns" "trends"  
  
  $`3`
  [1] "learning"   "analysis"   "machine"    "language"   "natural"   
  [6] "processing" "analytics" 
  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1"></a><span class="co"># Convert the community assignments to a character vector</span></span>
<span id="cb66-2"><a href="#cb66-2"></a>louvain_communities_char <span class="ot">&lt;-</span> <span class="fu">as.character</span>(louvain_communities<span class="sc">$</span>membership)</span>
<span id="cb66-3"><a href="#cb66-3"></a><span class="fu">names</span>(louvain_communities_char) <span class="ot">&lt;-</span> louvain_communities<span class="sc">$</span>names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-fig.dpi="200">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1"></a><span class="co"># Visualize the keyword network with community colors</span></span>
<span id="cb67-2"><a href="#cb67-2"></a><span class="fu">ggraph</span>(keyword_network) <span class="sc">+</span></span>
<span id="cb67-3"><a href="#cb67-3"></a>  <span class="fu">geom_edge_link</span>(<span class="fu">aes</span>(<span class="at">width =</span> n), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb67-4"><a href="#cb67-4"></a>  <span class="fu">geom_node_point</span>(<span class="fu">aes</span>(<span class="at">size =</span> degree_centrality,</span>
<span id="cb67-5"><a href="#cb67-5"></a>                      <span class="at">col =</span> louvain_communities_char)) <span class="sc">+</span></span>
<span id="cb67-6"><a href="#cb67-6"></a>  <span class="fu">geom_node_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> name, <span class="at">color =</span> louvain_communities_char), </span>
<span id="cb67-7"><a href="#cb67-7"></a>                 <span class="at">vjust =</span> <span class="fl">1.5</span>, <span class="at">hjust =</span> <span class="fl">1.5</span>,</span>
<span id="cb67-8"><a href="#cb67-8"></a>                 <span class="at">size =</span> <span class="dv">10</span>) <span class="sc">+</span></span>
<span id="cb67-9"><a href="#cb67-9"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">"Community"</span>) <span class="sc">+</span>  <span class="co"># add a legend for community colors</span></span>
<span id="cb67-10"><a href="#cb67-10"></a>  <span class="fu">theme_graph</span>(<span class="at">base_family =</span> <span class="st">"Arial"</span>) <span class="sc">+</span></span>
<span id="cb67-11"><a href="#cb67-11"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Keyword Network with Community Detection"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img data-src="index_files/figure-revealjs/unnamed-chunk-16-1.png" width="1440"></p>
</div>
</div>
</div>
</div>
</div>
</section><section id="applications-in-academic-research-1" class="slide level2"><h2>Applications in Academic Research</h2>
<hr>
<h3 id="literature-reviews-and-meta-analyses"><strong>Literature Reviews and Meta-Analyses:</strong></h3>
<div>
<ol type="1">
<li class="fragment"><p><strong>Summarization of articles</strong> <em>(Keywords and Topics)</em>: Text mining techniques can extract keywords and main topics from research articles, allowing researchers to quickly understand the content and focus of a given paper.</p></li>
<li class="fragment"><p><strong>Meta-analysis:</strong> By aggregating and analyzing findings from multiple research studies, text mining can help researchers <u>draw more reliable conclusions and identify patterns and trends across a body of literature</u>.</p></li>
<li class="fragment"><p><strong>Identifying research trends and gaps:</strong> Text mining can help researchers <u>identify emerging research trends, patterns, and potential gaps in the literature</u> by analyzing large collections of articles and tracking the frequency of specific terms, phrases, and topics over time.</p></li>
</ol>
<!-- --><ol start="4" type="1">
<li class="fragment"><p><strong>Analyzing online academic discussions:</strong> Researchers can use text mining <u>to analyze discussions from academic forums, social media, and other online platforms</u>, providing insights into prevailing opinions, questions, and debates within the research community.</p></li>
<li class="fragment"><p><strong>Citation network analysis:</strong> Text mining can be used to create <u>citation networks, which help researchers visualize the relationships between publications, authors, and research topics</u>, enabling them to identify influential works and collaboration patterns in their field.</p></li>
</ol>
</div>
</section><section id="applications-in-academic-research-2" class="slide level2"><h2>Applications in Academic Research</h2>
<hr>
<h3 id="social-media-analysis-for-public-opinion-on-academic-topics"><strong>Social Media Analysis for Public Opinion on Academic Topics:</strong></h3>
<div>
<ol type="1">
<li class="fragment"><p><strong>Trend, Keywords, and topic analysis:</strong> Text mining can be used to analyze social media content and identify popular trends, keywords, and topics related to academic research, giving researchers insights into public interest and awareness of their research area.</p></li>
<li class="fragment"><p><strong>Information flow:</strong> By tracking the spread of information on social media platforms, researchers can understand how academic research findings are disseminated and shared among different communities, helping them develop strategies to improve communication and outreach.</p></li>
<li class="fragment"><p><strong>Sentiment analysis:</strong> Text mining can be used to <u>analyze the sentiment of social media posts and comments related to academic research</u>, providing researchers with insights into public perceptions and opinions about specific research topics or findings.</p></li>
<li class="fragment"><p><strong>Network analysis (among actors, keywords, etc.):</strong> Researchers can use text mining to analyze the relationships among different actors (e.g., individuals, organizations, or countries) and keywords within social media networks, helping them identify key influencers, collaboration opportunities, and areas of common interest. This analysis can provide valuable insights into the broader impact and reach of their research within various communities.</p></li>
</ol>
</div>
</section><section id="applications-in-academic-research-3" class="slide level2"><h2>Applications in Academic Research</h2>
<hr>

<img data-src="img/fig_3.png" class="r-stretch"></section><section id="applications-in-academic-research-4" class="slide level2"><h2>Applications in Academic Research</h2>
<hr>

<img data-src="img/fig_4.png" class="r-stretch"></section><section id="applications-in-academic-research-5" class="slide level2"><h2>Applications in Academic Research</h2>
<hr>

<img data-src="img/fig_5.png" class="r-stretch"></section><section id="challenges-and-limitations-1" class="slide level2"><h2>Challenges and Limitations</h2>
<hr>
<p><br></p>
<p><strong>A. Handling unstructured and noisy data:</strong></p>
<ol type="1">
<li><p><strong>Heterogeneous formats:</strong> Academic research articles and texts come in various formats, such as PDFs, Word documents, and HTML. Text mining techniques need to handle and convert these diverse formats into structured data for analysis.</p></li>
<li><p><strong>Data cleaning:</strong> Raw text data usually contain typos, grammatical errors, and inconsistencies that can affect the accuracy of the analysis. Text mining techniques must be robust enough to address these issues and clean the data.</p></li>
<li><p><strong>Ambiguity:</strong> Text data often contain ambiguous terms, phrases, or sentences that can have multiple interpretations. Identifying and resolving these ambiguities is a significant challenge in text mining.</p></li>
</ol></section><section id="challenges-and-limitations-2" class="slide level2"><h2>Challenges and Limitations</h2>
<hr>
<p><br></p>
<p><strong>B. Addressing language and domain-specific challenges:</strong></p>
<ol type="1">
<li><p><strong>Multilingual texts:</strong> Academic research is published in multiple languages, requiring text mining techniques to be adaptable to different languages and character sets.</p></li>
<li><p><strong>Domain-specific jargon:</strong> Each research domain has its terminology and phrases that may not be easily understood by generic text mining tools. Developing techniques that can understand and analyze these domain-specific terms is crucial.</p></li>
<li><p><strong>Context-dependent meaning:</strong> The meaning of a term or phrase may vary depending on the context it is used in. Text mining techniques need to be able to accurately capture and understand these context-dependent meanings.</p></li>
</ol></section><section id="challenges-and-limitations-3" class="slide level2"><h2>Challenges and Limitations</h2>
<hr>
<p><br></p>
<p><strong>C. Ethical and legal considerations:</strong></p>
<ol type="1">
<li><p><strong>Data privacy:</strong> Text mining may involve processing sensitive information, such as personal or proprietary data. Researchers must ensure that they adhere to data privacy regulations and protect the confidentiality of the data.</p></li>
<li><p><strong>Copyright and intellectual property:</strong> Text mining techniques may involve the use of copyrighted material. It is essential to understand and comply with copyright laws and obtain the necessary permissions for using such content.</p></li>
<li><p><strong>Bias and fairness:</strong> Text mining algorithms can inadvertently perpetuate biases present in the training data. Researchers should be aware of potential biases and develop strategies to mitigate their impact on the analysis.</p></li>
</ol></section><section id="challenges-and-limitations-4" class="slide level2"><h2>Challenges and Limitations</h2>
<hr>
<p><br></p>
<p><strong>D. Scalability and computational complexity:</strong></p>
<ol type="1">
<li><p><strong>Large datasets:</strong> Academic research data can be vast, and text mining techniques need to be able to efficiently handle and process these large datasets.</p></li>
<li><p><strong>High dimensionality:</strong> Text data is inherently high-dimensional due to the vast number of unique words and phrases. Techniques must be able to manage this high dimensionality to avoid the “curse of dimensionality” and maintain computational efficiency.</p></li>
<li><p><strong>Real-time processing:</strong> In some cases, text mining applications may require real-time analysis and processing of text data. Developing techniques that can handle real-time processing demands while maintaining accuracy is a significant challenge.</p></li>
</ol></section><section id="conclusion-and-future-directions" class="slide level2"><h2>Conclusion and Future Directions</h2>
<hr>
<p><br></p>
<p><strong>A. The growing importance of text mining in academic research:</strong></p>
<ol type="1">
<li><p><strong>Expanding data sources:</strong> With the exponential growth of digital content and the increasing accessibility of various data sources, text mining will continue to play a pivotal role in extracting valuable information and insights from large volumes of unstructured data.</p></li>
<li><p><strong>Facilitating knowledge discovery:</strong> Text mining techniques enable researchers to identify patterns, trends, and relationships within and across research domains that may not be evident through traditional research methods.</p></li>
<li><p><strong>Enhancing research efficiency:</strong> By automating data analysis and processing tasks, text mining can save researchers time and resources, allowing them to focus on more in-depth analysis and interpretation of results.</p></li>
</ol></section><section id="conclusion-and-future-directions-1" class="slide level2"><h2>Conclusion and Future Directions</h2>
<hr>
<p><br></p>
<p><strong>B. Continued development of new techniques and methodologies:</strong></p>
<ol type="1">
<li><p><strong>Machine learning and artificial intelligence:</strong> The integration of machine learning and artificial intelligence methods into text mining will lead to more sophisticated and accurate analysis techniques, capable of handling complex and ambiguous language structures.</p></li>
<li><p><strong>Natural language processing advancements:</strong> Ongoing improvements in natural language processing will enable more accurate understanding and interpretation of human language in text data, leading to better results in text mining tasks.</p></li>
<li><p><strong>Domain-specific tools:</strong> The development of specialized text mining tools tailored to specific research domains will facilitate more accurate and efficient analysis of domain-specific jargon and concepts.</p></li>
</ol></section><section id="conclusion-and-future-directions-2" class="slide level2"><h2>Conclusion and Future Directions</h2>
<hr>
<p><br></p>
<p><strong>C. Encouraging interdisciplinary collaboration and research:</strong></p>
<ol type="1">
<li><p><strong>Cross-disciplinary partnerships:</strong> Collaborations between computer scientists, linguists, and domain experts will foster the development of novel techniques and approaches that address the unique challenges of text mining in specific research areas.</p></li>
<li><p><strong>Shared resources and infrastructure:</strong> Establishing shared platforms, datasets, and software tools will encourage researchers from different disciplines to explore text mining applications, promoting innovation and knowledge exchange.</p></li>
<li><p><strong>Training and education:</strong> Providing training and educational opportunities in text mining will help researchers across disciplines develop the skills needed to apply text mining techniques effectively in their research.</p></li>
</ol></section><section id="conclusion-and-future-directions-3" class="slide level2"><h2>Conclusion and Future Directions</h2>
<hr>
<p><br></p>
<p><strong>D. Addressing challenges and limitations for more robust applications:</strong></p>
<ol type="1">
<li><p><strong>Tackling unstructured and noisy data:</strong> Developing techniques to better handle, clean, and preprocess unstructured and noisy data will improve the accuracy and reliability of text mining applications in academic research.</p></li>
<li><p><strong>Addressing ethical and legal concerns:</strong> Researchers must continue to engage in discussions and develop guidelines to address data privacy, copyright, and intellectual property issues related to text mining.</p></li>
<li><p><strong>Improving scalability and computational efficiency:</strong> As the volume of data continues to grow, researchers need to develop more scalable and computationally efficient text mining techniques to handle large-scale datasets and real-time processing demands.</p></li>
</ol>

<img src="img/HYU_logo_singlecolor_png.png" class="slide-logo r-stretch"><div class="footer footer-default">

</div>
</section>
</div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="index_files/libs/revealjs/dist/reveal.js"></script><!-- reveal.js plugins --><script src="index_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script><script src="index_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script><script src="index_files/libs/revealjs/plugin/reveal-menu/menu.js"></script><script src="index_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script><script src="index_files/libs/revealjs/plugin/quarto-support/support.js"></script><script src="index_files/libs/revealjs/plugin/notes/notes.js"></script><script src="index_files/libs/revealjs/plugin/search/search.js"></script><script src="index_files/libs/revealjs/plugin/zoom/zoom.js"></script><script src="index_files/libs/revealjs/plugin/math/math.js"></script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1920,

        height: 1080,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script><script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script><script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>


</body></html>